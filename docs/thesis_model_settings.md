# å’è«–å‘ã‘ãƒ¢ãƒEƒ«è¨­å®šãƒ¡ãƒ¢

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€æœ¬ç ”ç©¶ã§ç”¨ãEŸåEƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«EENN-LSTMã€HiFi-GANã€Grad-CAM å¯è¦–åŒ–E‰ãEè©³ç´°è¨­å®šã‚’ã¾ã¨ã‚ã‚‹ã€‚å‰å‡¦çEEãƒEEã‚¿åˆE‰²ãƒ»ãƒ¢ãƒEƒ«æ§‹é€ ãƒ»æå¤±é–¢æ•°ãƒ»å­¦ç¿’ãƒã‚¤ãƒ‘ãEãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»å¯è¦–åŒ–æ‰‹é Eªã©ã€å’æ¥­è«–æ–‡è¨˜è¿°æ™‚ã«å‚çEã™ã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ãE‚‹ã€E
---

## 1. ãƒEEã‚¿å‰åEçE¼ˆåEé€šè¨­å®šï¼E
- **å‹•ç”»æ­£è¦åŒ–**
  - å…E‹•ç”»ã¯ 256ÃE56 ã®ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›ã—ã€ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«å¹³åE0 / æ¨™æº–åå·® 1 æ­£è¦åŒ–å¾Œã€Eã€E ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€E  - è¤E•°å‹•ç”»ã‚’æ‰±ãE ´åˆãE `preprocess_rtmri_data.py` ã‚’ä½¿ç”¨ã—ã¦ä¸€æ‹¬å‡¦çE€E 
    ä¾E  
    ```powershell
    python preprocess_rtmri_data.py `
      --data_dir <video_root> `
      --audio_dir <audio_root> `
      --out_dir dataset/rtmri_normalized_processed `
      --sr 11413 --n_mels 64 --n_fft 2048 --hop_length 420 `
      --win_length 2048 --preemph 0.97 --ref_frames 4
    ```
- **éŸ³å£°å‡¦çE*
  - ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒE11,413 Hz ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€ãEãƒªã‚¨ãƒ³ãƒ•ã‚¡ã‚·ã‚¹ä¿‚æ•° 0.97ã€ãƒ‘ãƒ¯ãƒ¼ãƒ¡ãƒ« (64 ãƒ¡ãƒ«) ã‚’ç®—åEå¾EdB å¤‰æ›ã€E  - `scaler.json` ã«ãƒ¡ãƒ«ã®å…¨ä½“å¹³åEæ¨™æº–åå·®ã‚’ä¿å­˜ã—ã€CNN-LSTM å­¦ç¿’æ™‚ã«æ­£è¦åŒ–ãƒ»å†æ¨™æº–åŒ–ã¸ä½¿ç”¨ã€E- **ãƒEEã‚¿ã‚»ãƒEƒˆæ§‹é€ **
  - `dataset/rtmri_normalized_processed/samples/<ID>/{mri.npy, mel_db.npy, mask.npy}`  
    `mask.npy` ã¯ç¾çŠ¶ 1 ã®ã¿Eˆå°E¥çšE«å£è…”ãEã‚¹ã‚¯ã‚’ä¹—ç®—äºˆå®šï¼‰ã€E  - 4 ãƒ•ãƒ¬ãƒ¼ãƒ å‚çEã®å›ºå®šé•·ãƒšã‚¢ã‚E`pairs_ref4` (npz)ã€`pairs_ref4_npy` (mmap ç”¨) ã«ä¿å­˜ã€E  - `scaler.json`ã€`meta.json`ã€`hifigan_filelists/{training,validation}.txt` ã‚’ä½µã›ã¦ç”ŸæEã€E
---

## 2. CNN-LSTMEˆãƒ¡ãƒ«ç”ŸæEå™¨EE
- **ãƒ¢ãƒEƒ«æ§‹é€ **EEmri2speech_code/mri_acoustic_model.py`EE  - EfficientNetV2-B2EEimm, `features_only=True`E‰ã§åEƒ•ãƒ¬ãƒ¼ãƒ ã®ç‰¹å¾´æŠ½å‡ºã€Ech MRI ã‚E3ch ã«è¤E£½ã—ã¦å…¥åŠ›ã€E  - Global Average Pooling â†EBiLSTMEEidden 640ã€åŒæ–¹å‘ãEå’Œï¼‰âE Dropout 0.5 â†ELinear (n_mels=64)ã€E- **å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `mri2speech_code/train_mri_acoustic_model.py`
  - DataLoader: `FixedLenPairDataset` + `collate_pad`ã€E0/10/10 ã®ãƒ©ãƒ³ãƒ€ãƒ åˆE‰² (`torch.utils.data.random_split`, seed=42)ã€E  - ãƒãƒƒãƒE `batch_size=16`ã€`micro_batch_size=4`Eˆå‹¾é…è“„ç©ï¼‰ã€`num_workers=4`ã€`prefetch_factor=4`ã€`pin_memory=True`ã€E  - Optimizer: `AdamW` (lr=1e-4, betas=(0.9,0.999), eps=1e-8, weight_decay=1e-4)ã€E  - Scheduler: `ReduceLROnPlateau` (factor=0.5, patience=5, min_lr=1e-6)ã€E  - Mixed Precision: bf16 (GPU ãŒå¯¾å¿E / fp16ã€èEå‹EGradScalerã€E  - å‹¾é…ã‚¯ãƒªãƒEE: `clip_grad_norm_=1.0`ã€E  - CNN éƒ¨åˆEE `torch.utils.checkpoint` ã‚’ä½¿ç”¨å¯èƒ½ (`--use_checkpoint --ckpt_segments 2`)ã€E- **æå¤±é–¢æ•° `MaskedMSEMAE` æ”¹è¨‚åEå®¹**
  - å‘¨æ³¢æ•°å¸¯åŸŸã”ã¨ã®é‡ã¿:
    - F0 (mel bin 0â€E): 2.0
    - F1 (6â€E5): 3.0
    - F2 (16â€E1): 2.4
    - F3 ä»˜è¿E(32â€E7): 1.6
    - é«˜åŸŸ (ä¸Šä½E16 bin): 1.8
  - æ™‚é–“æ–¹å‘ãEé‡ã¿: å…ˆé ­ 8 ãƒ•ãƒ¬ãƒ¼ãƒ ã« 1.6 â†E1.02 ã¾ã§æ®µéšçš„ã«å¼·èª¿ã€E  - Ramp è¨­å®E `ramp_steps=120000`ã€‚åEæœŸãEãƒ™ãEã‚¹é‡ã¿ã€ä»¥é™ã‚¿ãƒ¼ã‚²ãƒEƒˆé‡ã¿ã«é·ç§»ã€E  - ä»˜åŠ æå¤±: ÎE(ä¸€æ¬¡å·®åˆEãƒ»Î”ÎE(äºŒæ¬¡å·®åˆEãƒ»æœ€æ–°ãƒ•ãƒ¬ãƒ¼ãƒ  MSE ã‚’åŠ é‡ã€‚ä¿‚æ•°ã¯ ramp ã«å¿œã˜ã¦ `delta_coeff=0.3â†E.45`ã€`accel_coeff=0.1â†E.15`ã€`latest_coeff=0.2â†E.4`ã€E  - æå¤±å†E§ãƒãƒ³ãƒ‰åˆ¥ MAE ã‚’è¨ˆæ¸¬ã—ã€`band/train_*` / `band/val_*` ã¨ã—ã¦ TensorBoard ã«è¨˜éŒ²ã€E- **å­¦ç¿’è¨­å®E*
  - ç›®æ¨™ã‚¨ãƒãƒƒã‚¯ 4,500ã€‚`EarlyStopping` çšEªæŒ™å‹•: val loss æ”¹å–EŒ 20 å›é€£ç¶šã§å¾—ã‚‰ã‚ŒãªãE€ã¾ãŸãE LR ãŒæœ€å°å­¦ç¿’ç‡ä»¥ä¸‹ã«ãªã‚‹ã¨åœæ­¢ã€E  - ãƒ­ã‚°: `checkpoints/mri_acoustic_model_retrain/logs`EEensorBoardE‰ã¨ stdoutã€E  - æœ€è‰¯ãƒ¢ãƒEƒ«ã¯æŒE®Eckpt (`--out_ckpt`) ã«ä¿å­˜ã€E
---

## 3. HiFi-GANEˆãEã‚³ãƒ¼ãƒ€EE
- **åˆæœŸå€¤**: `checkpoints/jvs_11413_2048_scratch/g_00055000` ã‚’ã‚³ãƒ”ãEã—ã¦ã‚¹ã‚¿ãƒ¼ãƒˆã€E- **è¨­å®E* (`config_custom.json`)
  - ãƒãƒƒãƒã‚µã‚¤ã‚º 16ã€å­¦ç¿’ç‡ 5e-5ã€Adam (Î²1=0.8, Î²2=0.99)ã€lr_decay=0.999ã€E  - Segment size 8400ã€ãƒ¡ãƒ«è¨­å®šãE CNN-LSTM ã¨åŒä¸€ (n_mels=64, hop=420)ã€E  - Upsampling rates [10,7,3,2]ã€ResBlock kernel [3,7,11]ã€dilation [[1,3,5], â€¦]ã€E- **ãƒEEã‚¿**
  - éŸ³å£°ãƒªã‚¹ãƒE `dataset/rtmri_normalized_processed/hifigan_filelists/{training,validation}.txt`EEreprocess æ™‚ã«ä½œæEã€seed=42, valid 10%E‰ã€E  - ãƒ¡ãƒ«å…¥åŠE
    - CNN-LSTM äºˆæ¸¬ãƒ¡ãƒ« `mels_ft_log_normalized`
    - ground-truth ãƒ¡ãƒ« `mels_gt_log`EEscripts/export_groundtruth_mels.py` ã§ `samples/<ID>/mel_db.npy` ã‹ã‚‰ç”ŸæEEE  - Fine-tuning æ™‚ãE `--extra_mels_dir mels_gt_log --extra_mels_weight 0.8` ã§ 80% ã‚Eground-truthã€E0% ã‚’äºˆæ¸¬ãƒ¡ãƒ«ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€E- **å®Ÿè¡Œä¾E*
  ```powershell
  C:\Users\Yamane\hifigan-env\Scripts\python.exe train.py ^
    --config config_custom.json ^
    --input_wavs_dir "C:\Users\Yamane\Desktop\å±±æ ¹ç ”ç©¶ç”¨\audio_wav" ^
    --input_training_file "dataset\rtmri_normalized_processed\hifigan_filelists\training.txt" ^
    --input_validation_file "dataset\rtmri_normalized_processed\hifigan_filelists\validation.txt" ^
    --input_mels_dir "dataset\rtmri_normalized_processed\mels_ft_log_normalized" ^
    --extra_mels_dir "dataset\rtmri_normalized_processed\mels_gt_log" ^
    --extra_mels_weight 0.8 ^
    --checkpoint_path "checkpoints\jvs_11413_2048_ft_mri_mix_gt08" ^
    --fine_tuning 1
  ```
- **ãƒ­ã‚°/è©•ä¾¡**
  - TensorBoard: `checkpoints/jvs_11413_2048_ft_mri_mix_gt08/logs`
  - ãƒã‚§ãƒE‚¯ãƒã‚¤ãƒ³ãƒˆé–“ã®éŸ³è³ªæ¯”è¼E `scripts/run_mri_video_inference.py` ã‚’ç”¨ãE¦åE`g_*.pt` ã§æ¨è«–ã—ã€`output/mri_infer_mix_gt08/g_0006xxxx` ãªã©ã«ä¿å­˜ã€E
---

## 4. Grad-CAM å¯è¦–åŒ–

- **åŸºæœ¬ãƒEEãƒ«**: `scripts/mri_gradcam_formant.py`
  - EfficientNet ãƒãƒƒã‚¯ãƒœãEãƒ³ã®æœ€çµ‚ç‰¹å¾´ãƒãƒƒãƒ—ã‚’å–å¾—ã—ã€ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆå¸¯åŸE(ä¾E F1=300-900 Hz, F2=900-2500 Hz) ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ã‚¿ãƒ¼ã‚²ãƒEƒˆã¨ã—ã¦é€E¼æ’­ã€E  - GPU åˆ©ç”¨ (`--device cuda`) ãŒå¯èƒ½ã€EuDNN RNN é€E¼æ’­ã®åˆ¶ç´E«å¯¾å¿œã™ã‚‹ãŸã‚ã€æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚ä¸€æ™‚çš„ã« LSTM ã‚Etrain çŠ¶æ…‹ã«åˆE‚Šæ›¿ãˆã¦ãE‚‹ã€E  - å‡ºåŠE `gradcam_<band>_sequence.npy` (TÃE56ÃE56)ã€`gradcam_<band>_average.png`ã€æŒ‡å®šãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚ªãƒ¼ãƒãEãƒ¬ã‚¤ PNGã€E  - å®Ÿè¡Œä¾E
    ```powershell
    python scripts/mri_gradcam_formant.py `
      --video normalized_videos/000.mp4 `
      --mri-checkpoint checkpoints/mri_acoustic_model.pt `
      --scaler-json dataset/rtmri_normalized_processed/scaler.json `
      --output-dir output/gradcam_formant/000_mix_gt08_60k `
      --formant-band F1:300-900 --formant-band F2:900-2500 `
      --target-frames 60 90 120 --device cuda
    ```
- **åŒºé–“æŠ½å‡ºãƒ»ã‚¹ãƒ­ãƒ¼å†ç”Ÿ**
  - NumPy ã§ä»»æ„åŒºé–E(ä¾E 0.8ã€E.2 s) ã‚’æŠ½å‡ºãE`gradcam_F*_aSegment_sequence.npy` ã¨ã—ã¦ä¿å­˜ã€E  - `scripts/create_gradcam_video.py` ã§ãƒ’ãEãƒˆãEãƒEEã®ã¿ã®ã‚¹ãƒ­ãƒ¼å‹•ç”»ã‚’ç”Ÿæˆã€E    ```powershell
    python scripts/create_gradcam_video.py `
      --video normalized_videos/000.mp4 `
      --sequence output/gradcam_formant/000_mix_gt08_60k/gradcam_F1_sequence.npy `
      --start-frame 0 `
      --output output/gradcam_formant/F1_slow.mp4 `
      --fps 5 --repeat 4 --alpha 0.7
    ```
- **æ˜ åƒï¼‹éŸ³å£°ã‚ªãƒ¼ãƒãEãƒ¬ã‚¤**
  - `scripts/create_gradcam_overlay_video.py` ã§å…E‹•ç”»E‹ç”ŸæˆéŸ³å£°EEoutput/mri_infer_latest_ft/000_generated.wav` ç­‰ï¼‰ã‚’çµåˆã—ã€F1/F2 ã®ãƒ’ãEãƒˆãEãƒEEã‚’é‡ç•³ã€E    ```powershell
    python scripts/create_gradcam_overlay_video.py `
      --video normalized_videos/000.mp4 `
      --heatmap output/gradcam_formant/000_mix_gt08_60k/gradcam_F1_sequence.npy `
      --heatmap2 output/gradcam_formant/000_mix_gt08_60k/gradcam_F2_sequence.npy `
      --audio output/mri_infer_latest_ft/000_generated.wav `
      --output output/gradcam_formant/000_overlay.mp4 `
      --alpha 0.7 --resize 256 256
    ```
  - `--heatmap2` ã‚’çœç•¥ã™ã‚Œã°å˜ä¸€å¸¯åŸŸãEã¿ã®å¯è¦–åŒ–ã¨ãªã‚‹ã€E
---

## 5. ãƒ¡ãƒ¢

- æ–°ãŸãªãƒEEã‚¿ã‚»ãƒEƒˆã‚’ç”¨ãE‚‹å ´åˆã‚‚ã€ä¸Šè¨˜ãEå‰åEçEâ†ECNN-LSTM å†å­¦ç¿Eâ†EHiFi-GAN å¾®èª¿æ•´ â†EGrad-CAM å¯è¦–åŒ–ã®é E«æ‰‹é E‚’è¸ã‚ã°ã€æ—¢å­˜ç’°å¢E‚’æµç”¨ã—ã¦å†ç¾ã§ãã‚‹ã€E- æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãE `docs/thesis_model_settings.md` ã¨ã—ã¦ä¿å­˜ã—ã¦ãE‚‹ãŸã‚ã€è«–æ–‡åŸ·ç­E™‚ã«ã¯ã“ãEãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ãªãŒã‚‰è¨­å®šå€¤ã‚’è¨˜è¿°ã™ã‚‹ã“ã¨ã€E
